ls()
rm(kist=ls())
rm(list=ls())
divide(2,1)
## [1] 0.5
divide(denominator<-2,numerator<-1)  # yields 2, a wrong answer
divide <- function(numerator, denominator) { numerator/denominator }
View(divide)
library(ggplot2)
library(ggplot2)
library(ggplot2)
library(ggplot2)
ggplot(data.frame(x=u), aes(x=x)) + geom_density() +
geom_line(data=data.frame(x=x,y=f), aes(x=x,y=y), linetype=2)
ggplot(data.frame(x=u), aes(x=x)) + geom_density() + geom_line(data=data.frame(x=x,y=f), aes(x=x,y=y), linetype=2)
ggplot(data.frame(x=u), aes(x=x)) + geom_density() +
geom_line(data=data.frame(x=x,y=f), aes(x=x,y=y), linetype=2)
u <- rnorm(1000)
ggplot(data.frame(x=u), aes(x=x)) + geom_density() +
geom_line(data=data.frame(x=x,y=f), aes(x=x,y=y), linetype=2)
qnorm(0.75)
pnorm(0.6744898)
# German bank credit dataset
d <- read.table(paste('http://archive.ics.uci.edu/ml/','machine-learning-databases/statlog/german/german.data',sep=''),stringsAsFactors=F,header=F)
head(d)
# schema documentation or data dictionary
colnames(d) <- c('Status.of.existing.checking.account',
'Duration.in.month',  'Credit.history', 'Purpose',
'Credit.amount', 'Savings account/bonds',
'Present.employment.since',
'Installment.rate.in.percentage.of.disposable.income',
'Personal.status.and.sex', 'Other.debtors/guarantors',
'Present.residence.since', 'Property', 'Age.in.years',
'Other.installment.plans', 'Housing',
'Number.of.existing.credits.at.this.bank', 'Job',
'Number.of.people.being.liable.to.provide.maintenance.for',
'Telephone', 'foreign.worker', 'Good.Loan')
# postprocess
d$Good.Loan <- as.factor(ifelse(d$Good.Loan==1,'GoodLoan','BadLoan'))
# Building a map to interpret loan use codes
mapping <- list(
'A40'='car (new)',
'A41'='car (used)',
'A42'='furniture/equipment',
'A43'='radio/television',
'A44'='domestic appliances')
for(i in 1:(dim(d))[2]) {             	# Note: 1
if(class(d[,i])=='character') {
d[,i] <- as.factor(as.character(mapping[d[,i]]))  	# Note: 2
}
}
summary(d$Purpose)
# Summary of Good.Loan and Purpose
table(d$Purpose,d$Good.Loan)
source("~/Documents/1132/資料科學/code02.workWithR/lessStructure.R")
# Summary of Good.Loan and Purpose
table(d$Purpose,d$Good.Loan)
# 計算 Entropy
entropy <- function(cluster) {
probs <- table(cluster) / length(cluster)
return(-sum(probs * log2(probs), na.rm=TRUE))
}
# 計算 Mutual Information (MI)
mutual_info <- function(cluster1, cluster2) {
contingency_table <- table(cluster1, cluster2)
joint_probs <- contingency_table / sum(contingency_table)
row_probs <- rowSums(joint_probs)
col_probs <- colSums(joint_probs)
mi <- 0
for (i in seq_len(nrow(joint_probs))) {
for (j in seq_len(ncol(joint_probs))) {
if (joint_probs[i, j] > 0) {
mi <- mi + joint_probs[i, j] * log2(joint_probs[i, j] / (row_probs[i] * col_probs[j]))
}
}
}
return(mi)
}
# 計算 NMI
nmi <- function(cluster1, cluster2) {
mi <- mutual_info(cluster1, cluster2)
h1 <- entropy(cluster1)
h2 <- entropy(cluster2)
return(2 * mi / (h1 + h2))
}
# === 輸入你的分類結果 ===
# 這裡請填入你從圖片中統計出的數據
cluster1 <- c("A", "A", "A", "B", "B", "B", "B", "B", "B", "B")  # 範例
cluster2 <- c("A", "A", "B", "B", "B", "C", "C", "C", "C", "C")  # 範例
# 計算 NMI
nmi_value <- nmi(cluster1, cluster2)
cat("NMI =", round(nmi_value, 4), "\n")
install.packages("aricode")  # 如果尚未安裝 aricode，請先安裝
library(aricode)
# 定義兩個 clustering 結果（向量）
cluster1 <- c(1, 1, 1, 2, 2, 2, 2, 2, 2, 2)  # 第一個分群結果
cluster2 <- c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3)  # 第二個分群結果
# 計算 NMI
nmi_value <- NMI(cluster1, cluster2)
print(paste("NMI 值為:", nmi_value))
install.packages("entropy")  # 如果尚未安裝 entropy，請先安裝
library(entropy)
# 計算熵函數
entropy_calc <- function(labels) {
prob <- table(labels) / length(labels)  # 計算機率分布
return(-sum(prob * log2(prob)))         # 熵公式
}
# 計算互資訊函數
mutual_information <- function(cluster1, cluster2) {
joint_table <- table(cluster1, cluster2) / length(cluster1)  # 聯合機率分布
cluster1_prob <- rowSums(joint_table)  # P(Y)
cluster2_prob <- colSums(joint_table)  # P(C)
mi <- sum(joint_table * log2(joint_table / (cluster1_prob %o% cluster2_prob)), na.rm = TRUE)
return(mi)
}
# 計算 NMI
nmi_calc <- function(cluster1, cluster2) {
H_Y <- entropy_calc(cluster1)  # H(Y)
H_C <- entropy_calc(cluster2)  # H(C)
MI_YC <- mutual_information(cluster1, cluster2)  # I(Y;C)
return((2 * MI_YC) / (H_Y + H_C))
}
# 定義兩個 clustering 結果（向量）
cluster1 <- c(1, 1, 1, 2, 2, 2, 2, 2, 2, 2)  # 第一個分群結果
cluster2 <- c(1, 1, 2, 2, 2, 3, 3, 3, 3, 3)  # 第二個分群結果
# 計算 NMI
nmi_value <- nmi_calc(cluster1, cluster2)
print(paste("NMI 值為:", nmi_value))
source("~/Documents/1132/資料科學/Code_reference/code03.measure/AkismetFilter.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/spamExam.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/spamExam.R")
ans = -0.3(log2(0.3))-0.7(log2(0.7))
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R", echo=TRUE)
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/Code_reference/code03.measure/NMI_try.R")
source("~/Documents/1132/資料科學/finalproject-group-6/code/Null_model/Naive.R", echo=TRUE)
setwd("~/Documents/1132/資料科學/finalproject-group-6")
source("~/Documents/1132/資料科學/finalproject-group-6/code/Null_model/Naive.R", echo=TRUE)
source("~/Documents/1132/資料科學/finalproject-group-6/code/brocoli_predict_xgboost.R", echo=TRUE)
